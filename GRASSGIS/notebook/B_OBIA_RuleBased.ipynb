{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python code has been developped by [Taïs Grippa](https://github.com/tgrippa) (Université Libre de Bruxelles). \n",
    "\n",
    "Code developped on Ubuntu 22.04 (Ubuntu Jammy) and GRASS GIS 8.0.2 using the Docker environment [available here](https://github.com/tgrippa/Weaksupervision_Vaihingen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tempfile\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "import time \n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath(os.path.join(os.environ['HOME'],'github','SRC'))\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup environment variables for TAIS DESKTOP (Linux Mint + GRASS Dev)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the file in `../SRC/config.py`, containing the configuration parameters, according to your own computer setup. The following cell is used to run this file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "exec(open(os.path.join(os.environ['HOME'],'github','SRC', 'config.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GISBASE': '/usr/lib/grass78', 'PYTHONLIB': '/usr/bin/python3', 'gisdb': '/home/tais/GRASSDATA', 'location': 'flair-one', 'permanent_mapset': 'PERMANENT', 'locationepsg': '2154', 'outputfolder': '/home/tais/result', 'inputdir': '/home/tais/data'}\n"
     ]
    }
   ],
   "source": [
    "print(config_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legend': '/home/tais/github/Legend.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import functions that setup the environmental variables\n",
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH\t= /.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/grass78/bin:/usr/lib/grass78/script:/usr/lib/grass78/lib \t\n",
      "HOSTNAME\t= d35fee4c10cd \t\n",
      "DISPLAY\t= unix \t\n",
      "LANG\t= C.UTF-8 \t\n",
      "LC_ALL\t= C.UTF-8 \t\n",
      "JUPYTER_ENABLE_LAB\t= yes \t\n",
      "TINI_VERSION\t= v0.6.0 \t\n",
      "HOME\t= /home/tais \t\n",
      "GIT_PYTHON_REFRESH\t= quiet \t\n",
      "PYDEVD_USE_FRAME_EVAL\t= NO \t\n",
      "JPY_SESSION_NAME\t= /home/tais/github/GRASSGIS/notebook/B_OBIA_RuleBased.ipynb \t\n",
      "JPY_PARENT_PID\t= 7 \t\n",
      "TERM\t= xterm-color \t\n",
      "CLICOLOR\t= 1 \t\n",
      "PAGER\t= cat \t\n",
      "GIT_PAGER\t= cat \t\n",
      "MPLBACKEND\t= module://matplotlib_inline.backend_inline \t\n",
      "PYTHONPATH\t= :/usr/lib/grass78/etc/python:/usr/lib/grass78/etc/python/grass:/usr/lib/grass78/etc/python/grass/script \t\n",
      "LD_LIBRARY_PATH\t= :/usr/lib/grass78/lib \t\n",
      "GISBASE\t= /usr/lib/grass78 \t\n",
      "PYTHONLIB\t= /usr/bin/python3 \t\n",
      "GIS_LOCK\t= $$ \t\n",
      "GISRC\t= /home/tais/.grass7/rc \t\n"
     ]
    }
   ],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRASS GIS Python libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "# Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from grass.script import vector\n",
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time\n",
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name\n",
    "# Import function that check and create folder\n",
    "from mkdir import check_create_dir\n",
    "# Import function that check if GRASS GIS add-on is installed and install it if needed\n",
    "from gextension import check_install_addon\n",
    "# Import function for sorting string number naturally\n",
    "from sorting_natural import natural_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def launch_mapset(mapset):\n",
    "    #Declare empty list that will contain the messages to return\n",
    "    return_message = []\n",
    "    # Init\n",
    "    gsetup.init(config_parameters['GISBASE'], config_parameters['gisdb'], config_parameters['location'], mapset)\n",
    "    # Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "    return_message.append(check_location(config_parameters[\"gisdb\"],config_parameters['location'],config_parameters[\"locationepsg\"]))\n",
    "    # Check if mapset exists\n",
    "    return_message.append(check_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Change the current working GRASS GIS session mapset\n",
    "    return_message.append(working_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def segmentation(mapset):\n",
    "    # Image ID\n",
    "    image_id = int(mapset.split('_')[-1])\n",
    "    # Define computational region\n",
    "    gscript.run_command('g.region', overwrite=True, raster='red', save=\"region\")\n",
    "    # Define group of layers\n",
    "    gscript.run_command('g.remove', quiet=True, flags='f', type='group', name='top')\n",
    "    gscript.run_command('i.group', quiet=True, group='top', input=\"nir,red,green,blue\")\n",
    "    # gscript.run_command('i.group', group='top', input=\"nir,red,green,blue,ndsm\") # TODO: Test of nDSM in the segmentation  \n",
    "    # Unsupervised Segmentation parameter optimization \n",
    "    gscript.run_command('i.segment.uspo', quiet=True, overwrite=True, group='top', segment_map='best_segment', regions='region', segmentation_method='region_growing', \n",
    "                        threshold_start='0.005', threshold_stop='0.05', threshold_step='0.002', minsizes='50', memory='3000', processes='25')\n",
    "    # Trick the segment ID to be sure the ID is unique through all the images\n",
    "    #formula = \"segmentation = (%s*1000000) + best_segment_region_rank1\"%image_id\n",
    "    formula = \"segmentation = best_segment_region_rank1\"\n",
    "    gscript.mapcalc(formula, quiet=True, overwrite=True)\n",
    "    # Exportation\n",
    "    gscript.run_command('r.out.gdal', quiet=True, overwrite=True, flags='m', input='segmentation', \n",
    "                        output=os.path.join(config_parameters['outputfolder'],'segment_rast','segment_%s.tiff'%mapset), format='GTiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_stats(mapset):\n",
    "    # Define computational region\n",
    "    gscript.run_command('g.region', overwrite=True, raster='segmentation')\n",
    "    # Define list of raster on which to compute statistics\n",
    "    rast_layers=[]\n",
    "    rast_layers.append('red')\n",
    "    rast_layers.append('green')\n",
    "    rast_layers.append('blue')\n",
    "    rast_layers.append('nir')\n",
    "    rast_layers.append('ndvi')\n",
    "    rast_layers.append('ndsm')\n",
    "    rast_layers.append('text_green_DE')\n",
    "    rast_layers.append('text_green_Entr')\n",
    "    rast_layers.append('text_red_ASM')\n",
    "    rast_layers.append('text_red_IDM')\n",
    "    rast_layers.append('text_nir_DE')\n",
    "\n",
    "    try:\n",
    "        # Compute segment statistics\n",
    "        gscript.run_command('i.segment.stats', quiet=True, overwrite=True, map='segmentation',\n",
    "                            rasters=','.join(rast_layers), raster_statistics='stddev,coeff_var,sum,median,perc_90', \n",
    "                            area_measures='area,perimeter,compact_circle,compact_square,fd',\n",
    "                            csvfile=os.path.join(config_parameters['outputfolder'],'stats', 'stats_%s.csv'%mapset),\n",
    "                            vectormap='segment',\n",
    "                            processes='20')   \n",
    "    except:\n",
    "        print(\"execution of i.segment.stats failed using Python run_command function. Now try with bash script\")\n",
    "        # Create a temporary file\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".sh\", delete=False) as temp_file:\n",
    "            # Write the bash script content to the temporary file\n",
    "            temp_file.write(b'#!/bin/bash\\n')\n",
    "            content = 'grass /home/tais/GRASSDATA/flair-one/%s --exec i.segment.stats --o --q map=segmentation rasters=%s \\\n",
    "            raster_statistics=stddev,coeff_var,sum,median,perc_90 area_measures=area,perimeter,compact_circle,compact_square,fd \\\n",
    "            csvfile=%s vectormap=segment processes=20\\n'%(mapset,','.join(rast_layers),os.path.join(config_parameters['outputfolder'],'stats', 'stats_%s.csv'%mapset)) \n",
    "            temp_file.write(content.encode())\n",
    "        \n",
    "            # Close the temporary file\n",
    "            temp_file.close()\n",
    "            # Get the path of the temporary file\n",
    "            temp_file_path = temp_file.name\n",
    "        \n",
    "            try:\n",
    "                # Add execution permissions to the temporary file\n",
    "                os.chmod(temp_file_path, 0o755)\n",
    "                # Execute the temporary file\n",
    "                stdout = subprocess.run(['bash', temp_file_path])\n",
    "                print(stdout)        \n",
    "            \n",
    "            except:\n",
    "                print(\"i.segment.stats using bash script failed too. Please check\")\n",
    "        \n",
    "            finally:\n",
    "                # Clean up the temporary file\n",
    "                os.remove(temp_file_path)\n",
    "    # Export vector layer as GPKG\n",
    "    gscript.run_command('v.out.ogr', quiet=True, overwrite=True, input='segment', \n",
    "                        output=os.path.join(config_parameters['outputfolder'],'segment_vect', 'segment_%s.gpkg'%mapset), format='GPKG')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "import subprocess\n",
    "\n",
    "def cleaning_tmpfiles(mapset):\n",
    "    stdout = subprocess.run(['grass','--text',os.path.join(config_parameters['gisdb'],config_parameters['location'],mapset)], \n",
    "                            shell=True, capture_output=True, text=True)\n",
    "    stdout = subprocess.run(['rm', '-r', os.path.join(config_parameters['gisdb'],config_parameters['location'],mapset,'vector')])\n",
    "    stdout = subprocess.run(['mkdir', os.path.join(config_parameters['gisdb'],config_parameters['location'],mapset,'vector')])\n",
    "    return stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def worker(mapset):\n",
    "    # Launch a new mapset for this image\n",
    "    launch_mapset(mapset)\n",
    "    # Segmentation\n",
    "    segmentation(mapset)\n",
    "    # Compute statistics\n",
    "    compute_stats(mapset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create new directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder '/home/tais/result' already exists\n",
      "The folder '/home/tais/result/stats' already exists\n",
      "The folder '/home/tais/result/segment_rast' already exists\n",
      "The folder '/home/tais/result/segment_vect' already exists\n"
     ]
    }
   ],
   "source": [
    "# Check and create folder if needed\n",
    "check_create_dir(config_parameters['outputfolder'])\n",
    "check_create_dir(os.path.join(config_parameters['outputfolder'],'stats'))\n",
    "check_create_dir(os.path.join(config_parameters['outputfolder'],'segment_rast'))\n",
    "check_create_dir(os.path.join(config_parameters['outputfolder'],'segment_vect'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Segmentation (region growing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "\n",
    "def find_files(path, pattern):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in fnmatch.filter(files, pattern):\n",
    "            yield os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2950 train images\n"
     ]
    }
   ],
   "source": [
    "# Get a list of path to train images\n",
    "train_folder = os.path.join(config_parameters['inputdir'],'train')\n",
    "train_tupple = [(os.path.split(x)[-1].split('.tif')[0],x) for x in find_files(train_folder, \"IMG_*.tif\")]\n",
    "print(f'There are {len(train_tupple)} train images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_mapsets = os.listdir(os.path.join(config_parameters['gisdb'],config_parameters['location']))\n",
    "list_mapsets.remove('PERMANENT')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_mapsets = ['IMG_027772', 'IMG_027782', 'IMG_027769', 'IMG_027778', 'IMG_027766', 'IMG_027776', 'IMG_027787', 'IMG_027784', 'IMG_027783', 'IMG_027779']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2950 mapsets\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(list_mapsets)} mapsets')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "start_parallel = start_processing()\n",
    "ncores = 10\n",
    "p = Pool(ncores)\n",
    "output = p.map(cleaning_tmpfiles, list_mapsets[:]) # Cleaning temp files in the mapsets\n",
    "p.close()\n",
    "p.join()\n",
    "# Print\n",
    "print_processing_time(start_parallel, \"Computation (on %s cores) achieved in \"%(ncores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Launch processes in parallel\n",
    "start_parallel = start_processing()\n",
    "ncores = 10\n",
    "p = Pool(ncores)\n",
    "output = p.map(worker, list_mapsets[:10])  # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "# Print\n",
    "print_processing_time(start_parallel, \"Computation (on %s cores) achieved in \"%(ncores))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "source": [
    "worker(\"IMG_027779\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
