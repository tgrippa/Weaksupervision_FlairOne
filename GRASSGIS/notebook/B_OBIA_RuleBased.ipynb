{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python code has been developped by [Taïs Grippa](https://github.com/tgrippa) (Université Libre de Bruxelles). \n",
    "\n",
    "Code developped on Ubuntu 22.04 (Ubuntu Jammy) and GRASS GIS 8.0.2 using the Docker environment [available here](https://github.com/tgrippa/Weaksupervision_Vaihingen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4 (main, Jun 29 2022, 12:14:53) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tempfile\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "import time \n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('/home/tais/github/SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup environment variables for TAIS DESKTOP (Linux Mint + GRASS Dev)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the file in `../SRC/config.py`, containing the configuration parameters, according to your own computer setup. The following cell is used to run this file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run /home/tais/github/SRC/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GISBASE': '/usr/lib/grass78', 'PYTHONLIB': '/usr/bin/python3', 'gisdb': '/home/tais/GRASSDATA', 'location': 'flair-one', 'permanent_mapset': 'PERMANENT', 'locationepsg': '2154', 'outputfolder': '/home/tais/result', 'inputdir': '/home/tais/data'}\n"
     ]
    }
   ],
   "source": [
    "print(config_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legend': '/home/tais/github/Legend.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions that setup the environmental variables\n",
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH\t= /.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/grass78/bin:/usr/lib/grass78/script:/usr/lib/grass78/lib \t\n",
      "HOSTNAME\t= f6e49c08eb5b \t\n",
      "DISPLAY\t= unixlocalhost:10.0 \t\n",
      "LANG\t= C.UTF-8 \t\n",
      "LC_ALL\t= C.UTF-8 \t\n",
      "JUPYTER_ENABLE_LAB\t= yes \t\n",
      "TINI_VERSION\t= v0.6.0 \t\n",
      "HOME\t= /home/tais \t\n",
      "GIT_PYTHON_REFRESH\t= quiet \t\n",
      "JPY_PARENT_PID\t= 7 \t\n",
      "TERM\t= xterm-color \t\n",
      "CLICOLOR\t= 1 \t\n",
      "PAGER\t= cat \t\n",
      "GIT_PAGER\t= cat \t\n",
      "MPLBACKEND\t= module://matplotlib_inline.backend_inline \t\n",
      "PYTHONPATH\t= :/usr/lib/grass78/etc/python:/usr/lib/grass78/etc/python/grass:/usr/lib/grass78/etc/python/grass/script \t\n",
      "LD_LIBRARY_PATH\t= :/usr/lib/grass78/lib \t\n",
      "GISBASE\t= /usr/lib/grass78 \t\n",
      "PYTHONLIB\t= /usr/bin/python3 \t\n",
      "GIS_LOCK\t= $$ \t\n",
      "GISRC\t= /home/tais/.grass7/rc \t\n"
     ]
    }
   ],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRASS GIS Python libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "# Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grass.script import vector\n",
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time\n",
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name\n",
    "# Import function that check and create folder\n",
    "from mkdir import check_create_dir\n",
    "# Import function that check if GRASS GIS add-on is installed and install it if needed\n",
    "from gextension import check_install_addon\n",
    "# Import function for sorting string number naturally\n",
    "from sorting_natural import natural_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_mapset(mapset):\n",
    "    #Declare empty list that will contain the messages to return\n",
    "    return_message = []\n",
    "    # Init\n",
    "    gsetup.init(config_parameters['GISBASE'], config_parameters['gisdb'], config_parameters['location'], mapset)\n",
    "    # Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "    return_message.append(check_location(config_parameters[\"gisdb\"],config_parameters['location'],config_parameters[\"locationepsg\"]))\n",
    "    # Check if mapset exists\n",
    "    return_message.append(check_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Change the current working GRASS GIS session mapset\n",
    "    return_message.append(working_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(image_id):\n",
    "    # Define computational region\n",
    "    gscript.run_command('g.region', overwrite=True, raster='red', save=\"region\")\n",
    "    # Define group of layers\n",
    "    gscript.run_command('g.remove', flags='f', type='group', name='top')\n",
    "    gscript.run_command('i.group', group='top', input=\"nir,red,green,blue\")\n",
    "    # gscript.run_command('i.group', group='top', input=\"nir,red,green,blue,ndsm\") # TODO: Test of nDSM in the segmentation  \n",
    "    # Unsupervised Segmentation parameter optimization \n",
    "    gscript.run_command('i.segment.uspo', overwrite=True, group='top', segment_map='best_segment', regions='region', segmentation_method='region_growing', \n",
    "                        threshold_start='0.005', threshold_stop='0.05', threshold_step='0.002', minsizes='50', memory='3000', processes='25')\n",
    "    # Trick the segment ID to be sure the ID is unique through all the images\n",
    "    formula = \"segmentation = (%s*1000000) + best_segment_region_rank1\"%image_id\n",
    "    gscript.mapcalc(formula, overwrite=True)\n",
    "    # Exportation\n",
    "    gscript.run_command('r.out.gdal', overwrite=True, flags='m', input='segmentation', output='/home/tais/result/segment_rast/segment_%s.tiff'%image_id, format='GTiff')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def segmentation_with_slic(image_id):    # After trying this approach, it seems the gain in processing time is conter-balanced by a loss in quality. So, we don't use it at the end. \n",
    "    # Define computational region\n",
    "    gscript.run_command('g.region', overwrite=True, raster='TOP.red', save=\"region\")\n",
    "    # Define group of layers\n",
    "    gscript.run_command('g.remove', flags='f', type='group', name='top')\n",
    "    gscript.run_command('i.group', group='top', input=\"TOP.nir,TOP.red,TOP.green\")\n",
    "    # Slic SUPERPIXEL as first \n",
    "    gscript.run_command('i.superpixels.slic', overwrite=True, input='top', output='slic', step='4') \n",
    "    #gscript.run_command('i.superpixels.slic', overwrite=True, input='top', output='slic', num_pixels='20000')  \n",
    "    # Unsupervised Segmentation parameter optimization \n",
    "    gscript.run_command('i.segment.uspo', overwrite=True, group='top', seeds='slic', segment_map='best_segment', regions='region', segmentation_method='region_growing', \n",
    "                        threshold_start='0.005', threshold_stop='0.05', threshold_step='0.002', minsizes='50', memory='3000', processes='10')\n",
    "    # Trick the segment ID to be sure the ID is unique through all the images\n",
    "    formula = \"segmentation = (%s*1000000) + best_segment_region_rank1\"%image_id\n",
    "    gscript.mapcalc(formula, overwrite=True)\n",
    "    # Exportation\n",
    "    gscript.run_command('r.out.gdal', overwrite=True, flags='m', input='segmentation', output='/home/tais/result/segment_rast/segment_%s.tiff'%image_id, format='GTiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(image_id):\n",
    "    # Define computational region\n",
    "    gscript.run_command('g.region', overwrite=True, raster='segmentation')\n",
    "    # Define list of raster on which to compute statistics\n",
    "    rast_layers=[]\n",
    "    rast_layers.append('TOP.nir')\n",
    "    rast_layers.append('TOP.red')\n",
    "    rast_layers.append('TOP.green')\n",
    "    rast_layers.append('text_green_DE')\n",
    "    rast_layers.append('text_green_Entr')\n",
    "    rast_layers.append('text_red_ASM')\n",
    "    rast_layers.append('text_red_IDM')\n",
    "    rast_layers.append('text_nir_DE')\n",
    "    rast_layers.append('text_dsm_Entr')\n",
    "    rast_layers.append('text_dsm_DE')\n",
    "    rast_layers.append('ndvi')\n",
    "    # Compute segment statistics\n",
    "    gscript.run_command('i.segment.stats', overwrite=True, map='segmentation',\n",
    "                        rasters=','.join(rast_layers), raster_statistics='stddev,coeff_var,sum,median,perc_90', area_measures='area,perimeter,compact_circle,compact_square,fd',\n",
    "                        vectormap='segment', processes='20')   \n",
    "    # Compute mode of GTS (Ground truth label)\n",
    "    if image_id in config_parameters['images_val'] or image_id in config_parameters['images_classical_approach']:\n",
    "        gscript.run_command('r.zonal.classes', overwrite=True, zone_map='segmentation',\n",
    "                            raster='gts', statistics='mode', csvfile='/home/tais/result/stats/tmp_statszonal_%s.csv'%image_id, separator='comma')\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input='/home/tais/result/stats/tmp_statszonal_%s.csv'%image_id, output='tmp_table')\n",
    "        gscript.run_command('v.db.join', map='segment', column='cat', other_table='tmp_table', other_column='cat_', subset_columns='mode')\n",
    "        gscript.run_command('v.db.renamecolumn', map='segment', column='mode,gts_label')\n",
    "        os.remove('/home/tais/result/stats/tmp_statszonal_%s.csv'%image_id)\n",
    "    # Export vector layer as GPKG\n",
    "    gscript.run_command('v.out.ogr', overwrite=True, input='segment', output='/home/tais/result/segment_vect/segment_%s.gpkg'%image_id, format='GPKG')\n",
    "    # Export attribute table as CSV\n",
    "    gscript.run_command('v.db.select', overwrite=True, map='segment', separator='comma', file='/home/tais/result/stats/stats_%s.csv'%image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(job_tupple):\n",
    "    # Launch a new mapset for this image\n",
    "    launch_mapset(job_tupple[0])\n",
    "    # Segmentation\n",
    "    segmentation(image_id)\n",
    "    #segmentation_with_slic(image_id)\n",
    "    # Compute statistics\n",
    "    try:\n",
    "        compute_stats(image_id)\n",
    "    except:   # Sometimes, the execution failed and the grass gis mapset need to be 'cleaned' by opening and closing it with the following command\n",
    "        subprocess.check_call(['grass','--text','/home/tais/GRASSDATA/vaihingen/image_%s'%x])\n",
    "        compute_stats(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create new directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder '/home/tais/result' already exists\n",
      "The folder '/home/tais/result/stats' has been created\n",
      "The folder '/home/tais/result/segment_rast' has been created\n",
      "The folder '/home/tais/result/segment_vect' has been created\n"
     ]
    }
   ],
   "source": [
    "# Check and create folder if needed\n",
    "check_create_dir(config_parameters['outputfolder'])\n",
    "check_create_dir(os.path.join(config_parameters['outputfolder'],'stats'))\n",
    "check_create_dir(os.path.join(config_parameters['outputfolder'],'segment_rast'))\n",
    "check_create_dir(os.path.join(config_parameters['outputfolder'],'segment_vect'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Segmentation (region growing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "\n",
    "def find_files(path, pattern):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in fnmatch.filter(files, pattern):\n",
    "            yield os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2950 train images\n"
     ]
    }
   ],
   "source": [
    "# Get a list of path to train images\n",
    "train_folder = os.path.join(config_parameters['inputdir'],'train')\n",
    "train_tupple = [(os.path.split(x)[-1].split('.tif')[0],x) for x in find_files(train_folder, \"IMG_*.tif\")]\n",
    "print(f'There are {len(train_tupple)} train images')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Launch processes in parallel\n",
    "start_parallel = start_processing()\n",
    "ncores = 20\n",
    "p = Pool(ncores)\n",
    "output = p.map(worker, train_tupple[:50])  # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "# Print\n",
    "print_processing_time(start_parallel, \"Computation (on %s cores) achieved in \"%(ncores))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "worker('12')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_all = start_processing()\n",
    "for x in image_id_list[:]:\n",
    "    print(\"Processing image %s\"%x)\n",
    "    start_loop = start_processing()\n",
    "    worker(x)\n",
    "    print_processing_time(start_loop, \"Computation achieved for image %s in \"%x)\n",
    "print_processing_time(start_all, \"Computation achieved in \")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
